{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164d59ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import torch\n",
    "import spacy\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6335bf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare text using the spacy english pipeline (see https://spacy.io/models/en)\n",
    "# we'll use it to lemmatize the text, and determine which part of speech each\n",
    "# lemmatize edits words to become the 'root' word - e.g. holds -> hold;  rubs->rub\n",
    "# part of speech indicates if the item is a verb, nooun, punctuation, space and so on.\n",
    "# make sure that the text sent to spacy doesn't end with a period immediately followed by a newline,\n",
    "# instead, make sure there is a space between the period and the newline, so that the period \n",
    "# is correctly identified as punctuation.\n",
    "\n",
    "def prepare_texts(text):    \n",
    "    # Get a callable object from spaCy that processes the text - lemmatizes and determines part of speech\n",
    "\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    \n",
    "    # lemmatize the text, get part of speech, and remove spaces and punctuation\n",
    "    \n",
    "    lemmas = [tok.lemma_ for tok in nlp(text) if tok.pos_ not in [\"PUNCT\", \"SPACE\"]]\n",
    "    \n",
    "    # count the number of occurences of each word in the vocabulary\n",
    "    \n",
    "    freqs = Counter() \n",
    "    for w in lemmas:\n",
    "        freqs[w] += 1\n",
    "        \n",
    "    vocab = list(freqs.items())  # List of (word, occurrence)\n",
    "    \n",
    "    vocab = sorted(vocab, key=lambda item: item[1], reverse=True)  # Sort by decreasing frequency\n",
    "    print(vocab)\n",
    "    \n",
    "    # Create word->index dictionary and index->word dictionary\n",
    "    \n",
    "    v2i = {v[0]:i for i,v in enumerate(vocab)}\n",
    "    i2v = {i:v[0] for i,v in enumerate(vocab)}\n",
    "    \n",
    "    return lemmas, v2i, i2v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b38e8c2",
   "metadata": {},
   "source": [
    "#### This following function walks through each word, and looks at a window (of size 'window') of words and creates input/output prediction pairs, predicting each of the words surrounding the current word from the current word.  So here we say that we are 'predicting the context' from the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719dc852",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_preprocess_text(textlist, v2i, window):\n",
    "\n",
    "    # Predict context with word. Sample the context within a window size.\n",
    "\n",
    "    X, Y = [], []  # is the list of training/test samples\n",
    "    \n",
    "    # TO DO - create all the X,Y pairs\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408bd566",
   "metadata": {},
   "source": [
    "## Define Model that will be trained to produce word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1029c79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2vecModel(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size):\n",
    "        super().__init__()\n",
    "        # initialize word vectors to random numbers \n",
    "        \n",
    "        #TO DO\n",
    "        \n",
    "        # prediction function takes embedding as input, and predicts which word in vocabulary as output\n",
    "\n",
    "        #TO DO\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: torch.tensor of shape (bsz), bsz is the batch size\n",
    "        \"\"\"\n",
    "        #TO DO\n",
    "        return logits, e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3f6d07",
   "metadata": {},
   "source": [
    "#### The training function - give it the text and it does the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994f2e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_word2vec(textlist, window, embedding_size ):\n",
    "    # Set up a model with Skip-gram (predict context with word)\n",
    "    # textlist: a list of the strings\n",
    "    \n",
    "\n",
    "    \n",
    "    # Create the training data\n",
    "    \n",
    "    # TO DO\n",
    "    \n",
    "    # Split the training data\n",
    "    \n",
    "    # TO DO\n",
    "    \n",
    "    # instantiate the network & set up the optimizer\n",
    "    \n",
    "    # TO DO\n",
    "    \n",
    "    # training loop\n",
    "    \n",
    "    # TO DO\n",
    "    return network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d319523d",
   "metadata": {},
   "source": [
    "### Run Training and retrieve embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751b4c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = train_word2vec(lemmas)\n",
    "embedding = network.embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac1b7b6",
   "metadata": {},
   "source": [
    "#### Evaluate some properties of the word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aecc16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_embedding(embedding, most_frequent_from=0, most_frequent_to=40):\n",
    "    assert embedding.shape[1] == 2, \"This only supports visualizing 2-d embeddings!\"\n",
    "    \n",
    "    # TO DO\n",
    "    \n",
    "visualize_embedding(embedding.detach().numpy(), most_frequent_from=0, most_frequent_to=11)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
